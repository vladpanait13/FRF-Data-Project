{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gueLcMdnc7ew"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "from datetime import datetime\n",
        "import random\n",
        "import unicodedata\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_diacritics(text):\n",
        "    \"\"\"\n",
        "    Remove diacritics from text\n",
        "    Converts characters like ă, â, î, ș, ț to a, a, i, s, t\n",
        "    \"\"\"\n",
        "    # First normalize to NFD (decomposed form)\n",
        "    normalized = unicodedata.normalize('NFD', text)\n",
        "    # Filter out combining characters (the diacritics)\n",
        "    without_diacritics = ''.join(char for char in normalized if unicodedata.category(char) != 'Mn')\n",
        "    return without_diacritics\n",
        "\n",
        "def scrape_transfermarkt_squad(url, team_name=\"Unknown\"):\n",
        "    \"\"\"\n",
        "    Scrape player data from a Transfermarkt squad page\n",
        "    Returns a list of dictionaries with Player, Age, and Foot data\n",
        "    \"\"\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
        "        'Accept-Language': 'en-US,en;q=0.5',\n",
        "        'Accept-Encoding': 'gzip, deflate',\n",
        "        'Connection': 'keep-alive',\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        print(f\"Scraping {team_name}...\")\n",
        "        response = requests.get(url, headers=headers, timeout=20)\n",
        "\n",
        "        if response.status_code == 503:\n",
        "            print(f\"503 error for {team_name}. Waiting longer before retry...\")\n",
        "            time.sleep(30)  # Wait 30 seconds\n",
        "            response = requests.get(url, headers=headers, timeout=20)\n",
        "\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        players_data = []\n",
        "\n",
        "        # Find the squad table - looking for the detailed view table\n",
        "        squad_table = soup.find('table', class_='items')\n",
        "\n",
        "        if not squad_table:\n",
        "            print(f\"Could not find squad table for {team_name}\")\n",
        "            return []\n",
        "\n",
        "        # Find all player rows (skip header row)\n",
        "        player_rows = squad_table.find('tbody').find_all('tr', class_=['odd', 'even'])\n",
        "\n",
        "        for row in player_rows:\n",
        "            try:\n",
        "                # Extract player name\n",
        "                player_cell = row.find('td', class_='posrela')\n",
        "                if player_cell:\n",
        "                    player_link = player_cell.find('a')\n",
        "                    if player_link:\n",
        "                        player_name_raw = player_link.get_text(strip=True)\n",
        "                        # Remove diacritics from player name\n",
        "                        player_name = remove_diacritics(player_name_raw)\n",
        "                    else:\n",
        "                        continue\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "                # Extract age from Date of birth/Age column\n",
        "                # Find all td elements in the row\n",
        "                all_cells = row.find_all('td')\n",
        "                age = \"N/A\"\n",
        "\n",
        "                # Look through all cells to find the one with date and age format\n",
        "                for cell in all_cells:\n",
        "                    cell_text = cell.get_text(strip=True)\n",
        "                    # Look for pattern like \"02.08.1990 (34)\" where 34 is the age\n",
        "                    age_match = re.search(r'\\d{2}\\.\\d{2}\\.\\d{4}\\s*\\((\\d+)\\)', cell_text)\n",
        "                    if age_match:\n",
        "                        age = age_match.group(1)\n",
        "                        break\n",
        "\n",
        "                # If we still don't have age, try a more general parentheses pattern\n",
        "                if age == \"N/A\":\n",
        "                    for cell in all_cells:\n",
        "                        cell_text = cell.get_text(strip=True)\n",
        "                        age_match = re.search(r'\\((\\d+)\\)', cell_text)\n",
        "                        if age_match and len(age_match.group(1)) <= 2:  # Age should be 1-2 digits\n",
        "                            age = age_match.group(1)\n",
        "                            break\n",
        "\n",
        "                # Extract foot - should be in the \"Foot\" column\n",
        "                foot_cells = row.find_all('td')\n",
        "                foot = \"N/A\"\n",
        "\n",
        "                # Find the foot column (usually around index 7-8)\n",
        "                for i, cell in enumerate(foot_cells):\n",
        "                    cell_text = cell.get_text(strip=True).lower()\n",
        "                    if cell_text in ['right', 'left', 'both']:\n",
        "                        foot = cell_text.capitalize()\n",
        "                        break\n",
        "\n",
        "                # If we couldn't find foot in the expected way, try looking for specific column\n",
        "                if foot == \"N/A\":\n",
        "                    try:\n",
        "                        # Foot is typically in column index 7 or 8\n",
        "                        if len(foot_cells) > 7:\n",
        "                            foot_text = foot_cells[7].get_text(strip=True)\n",
        "                            if foot_text.lower() in ['right', 'left', 'both']:\n",
        "                                foot = foot_text.capitalize()\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                players_data.append({\n",
        "                    'Player': player_name,\n",
        "                    'Age': age,\n",
        "                    'Foot': foot,\n",
        "                    'Team': team_name\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing player row in {team_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"Successfully scraped {len(players_data)} players from {team_name}\")\n",
        "        return players_data\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request error for {team_name}: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error for {team_name}: {e}\")\n",
        "        return []\n",
        "\n",
        "def main():\n",
        "    # List of URLs and corresponding team names\n",
        "    urls_and_teams = [\n",
        "        (\"https://www.transfermarkt.com/fcsb/kader/verein/301/saison_id/2024/plus/1\", \"FCSB\"),\n",
        "        (\"https://www.transfermarkt.com/cfr-cluj/kader/verein/7769/saison_id/2024/plus/1\", \"CFR Cluj\"),\n",
        "        (\"https://www.transfermarkt.com/fc-rapid-1923/kader/verein/455/saison_id/2024/plus/1\", \"FC Rapid 1923\"),\n",
        "        (\"https://www.transfermarkt.com/universitatea-craiova/kader/verein/40812/saison_id/2024/plus/1\", \"Universitatea Craiova\"),\n",
        "        (\"https://www.transfermarkt.com/fc-universitatea-cluj/kader/verein/6429/saison_id/2024/plus/1\", \"FC Universitatea Cluj\"),\n",
        "        (\"https://www.transfermarkt.com/fc-dinamo/kader/verein/312/saison_id/2024/plus/1\", \"FC Dinamo\"),\n",
        "        (\"https://www.transfermarkt.com/sepsi-osk-sf-gheorghe/kader/verein/54585/saison_id/2024/plus/1\", \"Sepsi OSK\"),\n",
        "        (\"https://www.transfermarkt.com/fcv-farul-constanta/kader/verein/29831/saison_id/2024/plus/1\", \"FCV Farul Constanta\"),\n",
        "        (\"https://www.transfermarkt.com/petrolul-ploiesti/kader/verein/9465/saison_id/2024/plus/1\", \"Petrolul Ploiesti\"),\n",
        "        (\"https://www.transfermarkt.com/sc-otelul-galati/kader/verein/4959/saison_id/2024/plus/1\", \"SC Otelul Galati\"),\n",
        "        (\"https://www.transfermarkt.com/fc-hermannstadt/kader/verein/58049/saison_id/2024/plus/1\", \"FC Hermannstadt\"),\n",
        "        (\"https://www.transfermarkt.com/uta-arad/kader/verein/952/saison_id/2024/plus/1\", \"UTA Arad\"),\n",
        "        (\"https://www.transfermarkt.com/fc-botosani/kader/verein/8818/saison_id/2024/plus/1\", \"FC Botosani\"),\n",
        "        (\"https://www.transfermarkt.com/acsm-politehnica-iasi/kader/verein/33966/saison_id/2024/plus/1\", \"Politehnica Iasi\"),\n",
        "        (\"https://www.transfermarkt.com/fc-buzau/kader/verein/11380/saison_id/2024/plus/1\", \"FC Buzau\"),\n",
        "        (\"https://www.transfermarkt.com/afc-unirea-04-slobozia/kader/verein/29700/saison_id/2024/plus/1\", \"AFC Unirea Slobozia\")\n",
        "    ]\n",
        "\n",
        "    all_players = []\n",
        "\n",
        "    print(\"Starting Transfermarkt scraping...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for i, (url, team_name) in enumerate(urls_and_teams):\n",
        "        # Add random delay between 8-15 seconds to avoid rate limiting\n",
        "        if i > 0:  # Don't wait before the first request\n",
        "            wait_time = random.uniform(8, 15)\n",
        "            print(f\"Waiting {wait_time:.1f} seconds before next request...\")\n",
        "            time.sleep(wait_time)\n",
        "\n",
        "        players = scrape_transfermarkt_squad(url, team_name)\n",
        "        all_players.extend(players)\n",
        "\n",
        "        print(f\"Total players scraped so far: {len(all_players)}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    # Create DataFrame\n",
        "    if all_players:\n",
        "        df = pd.DataFrame(all_players)\n",
        "\n",
        "        # Remove the Team column for final output (keeping only Player, Age, Foot)\n",
        "        df_final = df[['Player', 'Age', 'Foot']].copy()\n",
        "\n",
        "        # Save to CSV\n",
        "        filename = f\"transfermarkt_players.csv\"\n",
        "        df_final.to_csv(filename, index=False)\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"SCRAPING COMPLETED!\")\n",
        "        print(f\"Total players scraped: {len(df_final)}\")\n",
        "        print(f\"Data saved to: {filename}\")\n",
        "\n",
        "        # Display summary\n",
        "        print(\"\\nSummary by team:\")\n",
        "        team_summary = df.groupby('Team').size().sort_values(ascending=False)\n",
        "        for team, count in team_summary.items():\n",
        "            print(f\"{team}: {count} players\")\n",
        "\n",
        "        print(f\"\\nFirst 10 rows of data:\")\n",
        "        print(df_final.head(10).to_string(index=False))\n",
        "\n",
        "        # Summary statistics\n",
        "        print(f\"\\nFoot distribution:\")\n",
        "        foot_dist = df_final['Foot'].value_counts()\n",
        "        print(foot_dist)\n",
        "\n",
        "    else:\n",
        "        print(\"No data was scraped. Please check the URLs and try again.\")\n",
        "\n",
        "# Run the scraper\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a1NXPn8dBos",
        "outputId": "f37153af-9708-44a8-e7fd-08a6a91090c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Transfermarkt scraping...\n",
            "==================================================\n",
            "Scraping FCSB...\n",
            "Successfully scraped 47 players from FCSB\n",
            "Total players scraped so far: 47\n",
            "------------------------------\n",
            "Waiting 11.0 seconds before next request...\n",
            "Scraping CFR Cluj...\n",
            "Successfully scraped 50 players from CFR Cluj\n",
            "Total players scraped so far: 97\n",
            "------------------------------\n",
            "Waiting 13.7 seconds before next request...\n",
            "Scraping FC Rapid 1923...\n",
            "Successfully scraped 48 players from FC Rapid 1923\n",
            "Total players scraped so far: 145\n",
            "------------------------------\n",
            "Waiting 9.6 seconds before next request...\n",
            "Scraping Universitatea Craiova...\n",
            "Successfully scraped 38 players from Universitatea Craiova\n",
            "Total players scraped so far: 183\n",
            "------------------------------\n",
            "Waiting 9.1 seconds before next request...\n",
            "Scraping FC Universitatea Cluj...\n",
            "Successfully scraped 37 players from FC Universitatea Cluj\n",
            "Total players scraped so far: 220\n",
            "------------------------------\n",
            "Waiting 10.4 seconds before next request...\n",
            "Scraping FC Dinamo...\n",
            "Successfully scraped 35 players from FC Dinamo\n",
            "Total players scraped so far: 255\n",
            "------------------------------\n",
            "Waiting 8.4 seconds before next request...\n",
            "Scraping Sepsi OSK...\n",
            "Successfully scraped 47 players from Sepsi OSK\n",
            "Total players scraped so far: 302\n",
            "------------------------------\n",
            "Waiting 8.3 seconds before next request...\n",
            "Scraping FCV Farul Constanta...\n",
            "Successfully scraped 53 players from FCV Farul Constanta\n",
            "Total players scraped so far: 355\n",
            "------------------------------\n",
            "Waiting 14.9 seconds before next request...\n",
            "Scraping Petrolul Ploiesti...\n",
            "Successfully scraped 43 players from Petrolul Ploiesti\n",
            "Total players scraped so far: 398\n",
            "------------------------------\n",
            "Waiting 11.7 seconds before next request...\n",
            "Scraping SC Otelul Galati...\n",
            "Successfully scraped 43 players from SC Otelul Galati\n",
            "Total players scraped so far: 441\n",
            "------------------------------\n",
            "Waiting 14.9 seconds before next request...\n",
            "Scraping FC Hermannstadt...\n",
            "Successfully scraped 29 players from FC Hermannstadt\n",
            "Total players scraped so far: 470\n",
            "------------------------------\n",
            "Waiting 13.4 seconds before next request...\n",
            "Scraping UTA Arad...\n",
            "Successfully scraped 50 players from UTA Arad\n",
            "Total players scraped so far: 520\n",
            "------------------------------\n",
            "Waiting 11.7 seconds before next request...\n",
            "Scraping FC Botosani...\n",
            "Successfully scraped 41 players from FC Botosani\n",
            "Total players scraped so far: 561\n",
            "------------------------------\n",
            "Waiting 13.9 seconds before next request...\n",
            "Scraping Politehnica Iasi...\n",
            "Successfully scraped 43 players from Politehnica Iasi\n",
            "Total players scraped so far: 604\n",
            "------------------------------\n",
            "Waiting 12.4 seconds before next request...\n",
            "Scraping FC Buzau...\n",
            "Successfully scraped 50 players from FC Buzau\n",
            "Total players scraped so far: 654\n",
            "------------------------------\n",
            "Waiting 14.8 seconds before next request...\n",
            "Scraping AFC Unirea Slobozia...\n",
            "Successfully scraped 33 players from AFC Unirea Slobozia\n",
            "Total players scraped so far: 687\n",
            "------------------------------\n",
            "\n",
            "==================================================\n",
            "SCRAPING COMPLETED!\n",
            "Total players scraped: 687\n",
            "Data saved to: transfermarkt_players.csv\n",
            "\n",
            "Summary by team:\n",
            "FCV Farul Constanta: 53 players\n",
            "CFR Cluj: 50 players\n",
            "UTA Arad: 50 players\n",
            "FC Buzau: 50 players\n",
            "FC Rapid 1923: 48 players\n",
            "Sepsi OSK: 47 players\n",
            "FCSB: 47 players\n",
            "Politehnica Iasi: 43 players\n",
            "SC Otelul Galati: 43 players\n",
            "Petrolul Ploiesti: 43 players\n",
            "FC Botosani: 41 players\n",
            "Universitatea Craiova: 38 players\n",
            "FC Universitatea Cluj: 37 players\n",
            "FC Dinamo: 35 players\n",
            "AFC Unirea Slobozia: 33 players\n",
            "FC Hermannstadt: 29 players\n",
            "\n",
            "First 10 rows of data:\n",
            "           Player Age  Foot\n",
            " Stefan Tarnovanu  25 Right\n",
            "       Lukas Zima  31 Right\n",
            "      Andrei Vlad  26 Right\n",
            "      Mihai Udrea  23  Left\n",
            "       Matei Popa  18   N/A\n",
            "Siyabonga Ngezana  27 Right\n",
            "     Joyskim Dawa  29 Right\n",
            "    Mihai Popescu  32 Right\n",
            "    Baba Alhassan  25 Right\n",
            "      Denis Harut  26 Right\n",
            "\n",
            "Foot distribution:\n",
            "Foot\n",
            "Right    388\n",
            "Left     148\n",
            "N/A      122\n",
            "Both      29\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}